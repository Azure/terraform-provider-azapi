[{"1":{"Kind":1}},{"1":{"Kind":2}},{"1":{"Kind":3}},{"1":{"Kind":4}},{"1":{"Kind":5}},{"1":{"Kind":6}},{"1":{"Kind":7}},{"1":{"Kind":8}},{"6":{"Value":"Microsoft.BatchAI/workspaces"}},{"6":{"Value":"2018-05-01"}},{"2":{"Name":"Microsoft.BatchAI/workspaces","Properties":{"id":{"Type":4,"Flags":10,"Description":"The resource id"},"name":{"Type":4,"Flags":9,"Description":"The resource name"},"type":{"Type":8,"Flags":10,"Description":"The resource type"},"apiVersion":{"Type":9,"Flags":10,"Description":"The resource api version"},"location":{"Type":4,"Flags":1,"Description":"The location of the resource"},"tags":{"Type":11,"Flags":0,"Description":"The tags of the resource"},"properties":{"Type":12,"Flags":2,"Description":"Workspace specific properties."}}}},{"2":{"Name":"WorkspaceCreateParametersTags","Properties":{},"AdditionalProperties":4}},{"2":{"Name":"WorkspaceProperties","Properties":{"creationTime":{"Type":4,"Flags":2,"Description":"Time when the Workspace was created."},"provisioningState":{"Type":17,"Flags":2,"Description":"Provisioning state of the cluster. Possible value are: creating - Specifies that the cluster is being created. succeeded - Specifies that the cluster has been created successfully. failed - Specifies that the cluster creation has failed. deleting - Specifies that the cluster is being deleted."},"provisioningStateTransitionTime":{"Type":4,"Flags":2,"Description":"The time at which the workspace entered its current provisioning state."}}}},{"6":{"Value":"creating"}},{"6":{"Value":"succeeded"}},{"6":{"Value":"failed"}},{"6":{"Value":"deleting"}},{"5":{"Elements":[13,14,15,16]}},{"4":{"Name":"Microsoft.BatchAI/workspaces@2018-05-01","ScopeType":8,"Body":10}},{"6":{"Value":"Microsoft.BatchAI/workspaces/experiments"}},{"6":{"Value":"2018-05-01"}},{"2":{"Name":"Microsoft.BatchAI/workspaces/experiments","Properties":{"id":{"Type":4,"Flags":10,"Description":"The resource id"},"name":{"Type":4,"Flags":9,"Description":"The resource name"},"type":{"Type":19,"Flags":10,"Description":"The resource type"},"apiVersion":{"Type":20,"Flags":10,"Description":"The resource api version"},"properties":{"Type":22,"Flags":2,"Description":"Experiment properties."}}}},{"2":{"Name":"ExperimentProperties","Properties":{"creationTime":{"Type":4,"Flags":2,"Description":"Time when the Experiment was created."},"provisioningState":{"Type":27,"Flags":2,"Description":"Provisioning state of the cluster. Possible value are: creating - Specifies that the cluster is being created. succeeded - Specifies that the cluster has been created successfully. failed - Specifies that the cluster creation has failed. deleting - Specifies that the cluster is being deleted."},"provisioningStateTransitionTime":{"Type":4,"Flags":2,"Description":"The time at which the experiment entered its current provisioning state."}}}},{"6":{"Value":"creating"}},{"6":{"Value":"succeeded"}},{"6":{"Value":"failed"}},{"6":{"Value":"deleting"}},{"5":{"Elements":[23,24,25,26]}},{"4":{"Name":"Microsoft.BatchAI/workspaces/experiments@2018-05-01","ScopeType":8,"Body":21}},{"6":{"Value":"Microsoft.BatchAI/workspaces/experiments/jobs"}},{"6":{"Value":"2018-05-01"}},{"2":{"Name":"Microsoft.BatchAI/workspaces/experiments/jobs","Properties":{"id":{"Type":4,"Flags":10,"Description":"The resource id"},"name":{"Type":4,"Flags":9,"Description":"The resource name"},"type":{"Type":29,"Flags":10,"Description":"The resource type"},"apiVersion":{"Type":30,"Flags":10,"Description":"The resource api version"},"properties":{"Type":32,"Flags":0,"Description":"Job properties."}}}},{"2":{"Name":"JobBaseProperties","Properties":{"schedulingPriority":{"Type":36,"Flags":0,"Description":"Scheduling priority associated with the job. Possible values: low, normal, high."},"cluster":{"Type":37,"Flags":1,"Description":"Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet."},"mountVolumes":{"Type":38,"Flags":0,"Description":"Details of volumes to mount on the cluster."},"nodeCount":{"Type":3,"Flags":1,"Description":"The job will be gang scheduled on that many compute nodes"},"containerSettings":{"Type":49,"Flags":0,"Description":"Docker container settings."},"cntkSettings":{"Type":52,"Flags":0,"Description":"CNTK (aka Microsoft Cognitive Toolkit) job settings."},"pyTorchSettings":{"Type":53,"Flags":0,"Description":"pyTorch job settings."},"tensorFlowSettings":{"Type":54,"Flags":0,"Description":"TensorFlow job settings."},"caffeSettings":{"Type":55,"Flags":0,"Description":"Caffe job settings."},"caffe2Settings":{"Type":56,"Flags":0,"Description":"Caffe2 job settings."},"chainerSettings":{"Type":57,"Flags":0,"Description":"Chainer job settings."},"customToolkitSettings":{"Type":58,"Flags":0,"Description":"Custom tool kit job settings."},"customMpiSettings":{"Type":59,"Flags":0,"Description":"Custom MPI job settings."},"horovodSettings":{"Type":60,"Flags":0,"Description":"Specifies the settings for Horovod job."},"jobPreparation":{"Type":61,"Flags":0,"Description":"Job preparation settings."},"stdOutErrPathPrefix":{"Type":4,"Flags":1,"Description":"The path where the Batch AI service stores stdout, stderror and execution log of the job."},"inputDirectories":{"Type":63,"Flags":0,"Description":"A list of input directories for the job."},"outputDirectories":{"Type":65,"Flags":0,"Description":"A list of output directories for the job."},"environmentVariables":{"Type":67,"Flags":0,"Description":"A collection of user defined environment variables to be setup for the job."},"secrets":{"Type":69,"Flags":0,"Description":"A collection of user defined environment variables with secret values to be setup for the job. Server will never report values of these variables back."},"constraints":{"Type":70,"Flags":0,"Description":"Constraints associated with the Job."},"toolType":{"Type":79,"Flags":2,"Description":"The toolkit type of the job."},"jobOutputDirectoryPathSegment":{"Type":4,"Flags":2,"Description":"A segment of job's output directories path created by Batch AI. Batch AI creates job's output directories under an unique path to avoid conflicts between jobs. This value contains a path segment generated by Batch AI to make the path unique and can be used to find the output directory on the node or mounted filesystem."},"creationTime":{"Type":4,"Flags":2,"Description":"The creation time of the job."},"provisioningState":{"Type":84,"Flags":2,"Description":"Provisioning state of the cluster. Possible value are: creating - Specifies that the cluster is being created. succeeded - Specifies that the cluster has been created successfully. failed - Specifies that the cluster creation has failed. deleting - Specifies that the cluster is being deleted."},"provisioningStateTransitionTime":{"Type":4,"Flags":2,"Description":"The time at which the job entered its current provisioning state."},"executionState":{"Type":90,"Flags":2,"Description":"The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job."},"executionStateTransitionTime":{"Type":4,"Flags":2,"Description":"The time at which the job entered its current execution state."},"executionInfo":{"Type":91,"Flags":2,"Description":"Information about the execution of a job."}}}},{"6":{"Value":"low"}},{"6":{"Value":"normal"}},{"6":{"Value":"high"}},{"5":{"Elements":[33,34,35]}},{"2":{"Name":"ResourceId","Properties":{"id":{"Type":4,"Flags":1,"Description":"The ID of the resource"}}}},{"2":{"Name":"MountVolumes","Properties":{"azureFileShares":{"Type":42,"Flags":0,"Description":"A collection of Azure File Shares that are to be mounted to the cluster nodes."},"azureBlobFileSystems":{"Type":44,"Flags":0,"Description":"A collection of Azure Blob Containers that are to be mounted to the cluster nodes."},"fileServers":{"Type":46,"Flags":0,"Description":"A collection of Batch AI File Servers that are to be mounted to the cluster nodes."},"unmanagedFileSystems":{"Type":48,"Flags":0,"Description":"A collection of unmanaged file systems that are to be mounted to the cluster nodes."}}}},{"2":{"Name":"AzureFileShareReference","Properties":{"accountName":{"Type":4,"Flags":1,"Description":"Name of the Azure storage account."},"azureFileUrl":{"Type":4,"Flags":1,"Description":"URL to access the Azure File."},"credentials":{"Type":40,"Flags":1,"Description":"Azure storage account credentials."},"relativeMountPath":{"Type":4,"Flags":1,"Description":"The relative path on the compute node where the Azure File share will be mounted. Note that all cluster level file shares will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level file shares will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT."},"fileMode":{"Type":4,"Flags":0,"Description":"File mode for files on the mounted file share. Default value: 0777."},"directoryMode":{"Type":4,"Flags":0,"Description":"File mode for directories on the mounted file share. Default value: 0777."}}}},{"2":{"Name":"AzureStorageCredentialsInfo","Properties":{"accountKey":{"Type":4,"Flags":0,"Description":"Storage account key. One of accountKey or accountKeySecretReference must be specified."},"accountKeySecretReference":{"Type":41,"Flags":0,"Description":"Key Vault Secret reference."}}}},{"2":{"Name":"KeyVaultSecretReference","Properties":{"sourceVault":{"Type":37,"Flags":1,"Description":"Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet."},"secretUrl":{"Type":4,"Flags":1,"Description":"The URL referencing a secret in the Key Vault."}}}},{"3":{"ItemType":39}},{"2":{"Name":"AzureBlobFileSystemReference","Properties":{"accountName":{"Type":4,"Flags":1,"Description":"Name of the Azure storage account."},"containerName":{"Type":4,"Flags":1,"Description":"Name of the Azure Blob Storage container to mount on the cluster."},"credentials":{"Type":40,"Flags":1,"Description":"Azure storage account credentials."},"relativeMountPath":{"Type":4,"Flags":1,"Description":"The relative path on the compute node where the Azure File container will be mounted. Note that all cluster level containers will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level containers will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT."},"mountOptions":{"Type":4,"Flags":0,"Description":"Mount options for mounting blobfuse file system."}}}},{"3":{"ItemType":43}},{"2":{"Name":"FileServerReference","Properties":{"fileServer":{"Type":37,"Flags":1,"Description":"Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet."},"sourceDirectory":{"Type":4,"Flags":0,"Description":"File Server directory that needs to be mounted. If this property is not specified, the entire File Server will be mounted."},"relativeMountPath":{"Type":4,"Flags":1,"Description":"The relative path on the compute node where the File Server will be mounted. Note that all cluster level file servers will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level file servers will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT."},"mountOptions":{"Type":4,"Flags":0,"Description":"Mount options to be passed to mount command."}}}},{"3":{"ItemType":45}},{"2":{"Name":"UnmanagedFileSystemReference","Properties":{"mountCommand":{"Type":4,"Flags":1,"Description":"Mount command line. Note, Batch AI will append mount path to the command on its own."},"relativeMountPath":{"Type":4,"Flags":1,"Description":"The relative path on the compute node where the unmanaged file system will be mounted. Note that all cluster level unmanaged file systems will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level unmanaged file systems will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT."}}}},{"3":{"ItemType":47}},{"2":{"Name":"ContainerSettings","Properties":{"imageSourceRegistry":{"Type":50,"Flags":1,"Description":"Information about docker image for the job."},"shmSize":{"Type":4,"Flags":0,"Description":"Size of /dev/shm. Please refer to docker documentation for supported argument formats."}}}},{"2":{"Name":"ImageSourceRegistry","Properties":{"serverUrl":{"Type":4,"Flags":0,"Description":"URL for image repository."},"image":{"Type":4,"Flags":1,"Description":"The name of the image in the image repository."},"credentials":{"Type":51,"Flags":0,"Description":"Credentials to access a container image in a private repository."}}}},{"2":{"Name":"PrivateRegistryCredentials","Properties":{"username":{"Type":4,"Flags":1,"Description":"User name to login to the repository."},"password":{"Type":4,"Flags":0,"Description":"User password to login to the docker repository. One of password or passwordSecretReference must be specified."},"passwordSecretReference":{"Type":41,"Flags":0,"Description":"Key Vault Secret reference."}}}},{"2":{"Name":"CNTKsettings","Properties":{"languageType":{"Type":4,"Flags":0,"Description":"The language to use for launching CNTK (aka Microsoft Cognitive Toolkit) job. Valid values are 'BrainScript' or 'Python'."},"configFilePath":{"Type":4,"Flags":0,"Description":"Specifies the path of the BrainScript config file. This property can be specified only if the languageType is 'BrainScript'."},"pythonScriptFilePath":{"Type":4,"Flags":0,"Description":"Python script to execute. This property can be specified only if the languageType is 'Python'."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter. This property can be specified only if the languageType is 'Python'."},"commandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script or cntk executable."},"processCount":{"Type":3,"Flags":0,"Description":"Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property"}}}},{"2":{"Name":"PyTorchSettings","Properties":{"pythonScriptFilePath":{"Type":4,"Flags":1,"Description":"The python script to execute."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter."},"commandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script."},"processCount":{"Type":3,"Flags":0,"Description":"Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property"},"communicationBackend":{"Type":4,"Flags":0,"Description":"Type of the communication backend for distributed jobs. Valid values are 'TCP', 'Gloo' or 'MPI'. Not required for non-distributed jobs."}}}},{"2":{"Name":"TensorFlowSettings","Properties":{"pythonScriptFilePath":{"Type":4,"Flags":1,"Description":"The python script to execute."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter."},"masterCommandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script for the master task."},"workerCommandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script for the worker task. Optional for single process jobs."},"parameterServerCommandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script for the parameter server. Optional for single process jobs."},"workerCount":{"Type":3,"Flags":0,"Description":"The number of worker tasks. If specified, the value must be less than or equal to (nodeCount * numberOfGPUs per VM). If not specified, the default value is equal to nodeCount. This property can be specified only for distributed TensorFlow training."},"parameterServerCount":{"Type":3,"Flags":0,"Description":"The number of parameter server tasks. If specified, the value must be less than or equal to nodeCount. If not specified, the default value is equal to 1 for distributed TensorFlow training. This property can be specified only for distributed TensorFlow training."}}}},{"2":{"Name":"CaffeSettings","Properties":{"configFilePath":{"Type":4,"Flags":0,"Description":"Path of the config file for the job. This property cannot be specified if pythonScriptFilePath is specified."},"pythonScriptFilePath":{"Type":4,"Flags":0,"Description":"Python script to execute. This property cannot be specified if configFilePath is specified."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter. The property can be specified only if the pythonScriptFilePath is specified."},"commandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the Caffe job."},"processCount":{"Type":3,"Flags":0,"Description":"Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property"}}}},{"2":{"Name":"Caffe2Settings","Properties":{"pythonScriptFilePath":{"Type":4,"Flags":1,"Description":"The python script to execute."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter."},"commandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script."}}}},{"2":{"Name":"ChainerSettings","Properties":{"pythonScriptFilePath":{"Type":4,"Flags":1,"Description":"The python script to execute."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter."},"commandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script."},"processCount":{"Type":3,"Flags":0,"Description":"Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property"}}}},{"2":{"Name":"CustomToolkitSettings","Properties":{"commandLine":{"Type":4,"Flags":0,"Description":"The command line to execute on the master node."}}}},{"2":{"Name":"CustomMpiSettings","Properties":{"commandLine":{"Type":4,"Flags":1,"Description":"The command line to be executed by mpi runtime on each compute node."},"processCount":{"Type":3,"Flags":0,"Description":"Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property"}}}},{"2":{"Name":"HorovodSettings","Properties":{"pythonScriptFilePath":{"Type":4,"Flags":1,"Description":"The python script to execute."},"pythonInterpreterPath":{"Type":4,"Flags":0,"Description":"The path to the Python interpreter."},"commandLineArgs":{"Type":4,"Flags":0,"Description":"Command line arguments that need to be passed to the python script."},"processCount":{"Type":3,"Flags":0,"Description":"Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property"}}}},{"2":{"Name":"JobPreparation","Properties":{"commandLine":{"Type":4,"Flags":1,"Description":"The command line to execute. If containerSettings is specified on the job, this commandLine will be executed in the same container as job. Otherwise it will be executed on the node."}}}},{"2":{"Name":"InputDirectory","Properties":{"id":{"Type":4,"Flags":1,"Description":"The ID for the input directory. The job can use AZ_BATCHAI_INPUT_<id> environment variable to find the directory path, where <id> is the value of id attribute."},"path":{"Type":4,"Flags":1,"Description":"The path to the input directory."}}}},{"3":{"ItemType":62}},{"2":{"Name":"OutputDirectory","Properties":{"id":{"Type":4,"Flags":1,"Description":"The ID of the output directory. The job can use AZ_BATCHAI_OUTPUT_<id> environment variable to find the directory path, where <id> is the value of id attribute."},"pathPrefix":{"Type":4,"Flags":1,"Description":"The prefix path where the output directory will be created. Note, this is an absolute path to prefix. E.g. $AZ_BATCHAI_MOUNT_ROOT/MyNFS/MyLogs. The full path to the output directory by combining pathPrefix, jobOutputDirectoryPathSegment (reported by get job) and pathSuffix."},"pathSuffix":{"Type":4,"Flags":0,"Description":"The suffix path where the output directory will be created. E.g. models. You can find the full path to the output directory by combining pathPrefix, jobOutputDirectoryPathSegment (reported by get job) and pathSuffix."}}}},{"3":{"ItemType":64}},{"2":{"Name":"EnvironmentVariable","Properties":{"name":{"Type":4,"Flags":1,"Description":"The name of the environment variable."},"value":{"Type":4,"Flags":1,"Description":"The value of the environment variable."}}}},{"3":{"ItemType":66}},{"2":{"Name":"EnvironmentVariableWithSecretValue","Properties":{"name":{"Type":4,"Flags":1,"Description":"The name of the environment variable to store the secret value."},"value":{"Type":4,"Flags":0,"Description":"The value of the environment variable. This value will never be reported back by Batch AI."},"valueSecretReference":{"Type":41,"Flags":0,"Description":"Key Vault Secret reference."}}}},{"3":{"ItemType":68}},{"2":{"Name":"JobBasePropertiesConstraints","Properties":{"maxWallClockTime":{"Type":4,"Flags":0,"Description":"Max time the job can run. Default value: 1 week."}}}},{"6":{"Value":"cntk"}},{"6":{"Value":"tensorflow"}},{"6":{"Value":"caffe"}},{"6":{"Value":"caffe2"}},{"6":{"Value":"chainer"}},{"6":{"Value":"horovod"}},{"6":{"Value":"custommpi"}},{"6":{"Value":"custom"}},{"5":{"Elements":[71,72,73,74,75,76,77,78]}},{"6":{"Value":"creating"}},{"6":{"Value":"succeeded"}},{"6":{"Value":"failed"}},{"6":{"Value":"deleting"}},{"5":{"Elements":[80,81,82,83]}},{"6":{"Value":"queued"}},{"6":{"Value":"running"}},{"6":{"Value":"terminating"}},{"6":{"Value":"succeeded"}},{"6":{"Value":"failed"}},{"5":{"Elements":[85,86,87,88,89]}},{"2":{"Name":"JobPropertiesExecutionInfo","Properties":{"startTime":{"Type":4,"Flags":2,"Description":"The time at which the job started running. 'Running' corresponds to the running state. If the job has been restarted or retried, this is the most recent time at which the job started running. This property is present only for job that are in the running or completed state."},"endTime":{"Type":4,"Flags":2,"Description":"The time at which the job completed. This property is only returned if the job is in completed state."},"exitCode":{"Type":3,"Flags":2,"Description":"The exit code of the job. This property is only returned if the job is in completed state."},"errors":{"Type":95,"Flags":2,"Description":"A collection of errors encountered by the service during job execution."}}}},{"2":{"Name":"BatchAIError","Properties":{"code":{"Type":4,"Flags":2,"Description":"An identifier of the error. Codes are invariant and are intended to be consumed programmatically."},"message":{"Type":4,"Flags":2,"Description":"A message describing the error, intended to be suitable for display in a user interface."},"details":{"Type":94,"Flags":2,"Description":"A list of additional details about the error."}}}},{"2":{"Name":"NameValuePair","Properties":{"name":{"Type":4,"Flags":2,"Description":"The name in the name-value pair."},"value":{"Type":4,"Flags":2,"Description":"The value in the name-value pair."}}}},{"3":{"ItemType":93}},{"3":{"ItemType":92}},{"4":{"Name":"Microsoft.BatchAI/workspaces/experiments/jobs@2018-05-01","ScopeType":8,"Body":31}},{"6":{"Value":"Microsoft.BatchAI/workspaces/fileServers"}},{"6":{"Value":"2018-05-01"}},{"2":{"Name":"Microsoft.BatchAI/workspaces/fileServers","Properties":{"id":{"Type":4,"Flags":10,"Description":"The resource id"},"name":{"Type":4,"Flags":9,"Description":"The resource name"},"type":{"Type":97,"Flags":10,"Description":"The resource type"},"apiVersion":{"Type":98,"Flags":10,"Description":"The resource api version"},"properties":{"Type":100,"Flags":0,"Description":"The properties of a file server."}}}},{"2":{"Name":"FileServerBaseProperties","Properties":{"vmSize":{"Type":4,"Flags":1,"Description":"The size of the virtual machine for the File Server. For information about available VM sizes from the Virtual Machines Marketplace, see Sizes for Virtual Machines (Linux)."},"sshConfiguration":{"Type":101,"Flags":1,"Description":"SSH configuration."},"dataDisks":{"Type":104,"Flags":1,"Description":"Data disks settings."},"subnet":{"Type":37,"Flags":0,"Description":"Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet."}}}},{"2":{"Name":"SshConfiguration","Properties":{"publicIPsToAllow":{"Type":102,"Flags":0,"Description":"List of source IP ranges to allow SSH connection from. The default value is '*' (all source IPs are allowed). Maximum number of IP ranges that can be specified is 400."},"userAccountSettings":{"Type":103,"Flags":1,"Description":"Settings for user account that gets created on each on the nodes of a cluster."}}}},{"3":{"ItemType":4}},{"2":{"Name":"UserAccountSettings","Properties":{"adminUserName":{"Type":4,"Flags":1,"Description":"Name of the administrator user account which can be used to SSH to nodes."},"adminUserSshPublicKey":{"Type":4,"Flags":0,"Description":"SSH public key of the administrator user account."},"adminUserPassword":{"Type":4,"Flags":0,"Description":"Password of the administrator user account."}}}},{"2":{"Name":"DataDisks","Properties":{"diskSizeInGB":{"Type":3,"Flags":1,"Description":"Disk size in GB for the blank data disks."},"cachingType":{"Type":108,"Flags":0,"Description":"Caching type for the disks. Available values are none (default), readonly, readwrite. Caching type can be set only for VM sizes supporting premium storage."},"diskCount":{"Type":3,"Flags":1,"Description":"Number of data disks attached to the File Server. If multiple disks attached, they will be configured in RAID level 0."},"storageAccountType":{"Type":111,"Flags":1,"Description":"Type of storage account to be used on the disk. Possible values are: Standard_LRS or Premium_LRS. Premium storage account type can only be used with VM sizes supporting premium storage."}}}},{"6":{"Value":"none"}},{"6":{"Value":"readonly"}},{"6":{"Value":"readwrite"}},{"5":{"Elements":[105,106,107]}},{"6":{"Value":"Standard_LRS"}},{"6":{"Value":"Premium_LRS"}},{"5":{"Elements":[109,110]}},{"4":{"Name":"Microsoft.BatchAI/workspaces/fileServers@2018-05-01","ScopeType":8,"Body":99}},{"6":{"Value":"Microsoft.BatchAI/workspaces/clusters"}},{"6":{"Value":"2018-05-01"}},{"2":{"Name":"Microsoft.BatchAI/workspaces/clusters","Properties":{"id":{"Type":4,"Flags":10,"Description":"The resource id"},"name":{"Type":4,"Flags":9,"Description":"The resource name"},"type":{"Type":113,"Flags":10,"Description":"The resource type"},"apiVersion":{"Type":114,"Flags":10,"Description":"The resource api version"},"properties":{"Type":116,"Flags":0,"Description":"Cluster properties."}}}},{"2":{"Name":"ClusterBaseProperties","Properties":{"vmSize":{"Type":4,"Flags":1,"Description":"The size of the virtual machines in the cluster. All nodes in a cluster have the same VM size."},"vmPriority":{"Type":119,"Flags":0,"Description":"VM priority. Allowed values are: dedicated (default) and lowpriority."},"scaleSettings":{"Type":120,"Flags":0,"Description":"At least one of manual or autoScale settings must be specified. Only one of manual or autoScale settings can be specified. If autoScale settings are specified, the system automatically scales the cluster up and down (within the supplied limits) based on the pending jobs on the cluster."},"virtualMachineConfiguration":{"Type":127,"Flags":0,"Description":"VM configuration."},"nodeSetup":{"Type":129,"Flags":0,"Description":"Node setup settings."},"userAccountSettings":{"Type":103,"Flags":1,"Description":"Settings for user account that gets created on each on the nodes of a cluster."},"subnet":{"Type":37,"Flags":0,"Description":"Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet."},"creationTime":{"Type":4,"Flags":2,"Description":"The time when the cluster was created."},"provisioningState":{"Type":139,"Flags":2,"Description":"Provisioning state of the cluster. Possible value are: creating - Specifies that the cluster is being created. succeeded - Specifies that the cluster has been created successfully. failed - Specifies that the cluster creation has failed. deleting - Specifies that the cluster is being deleted."},"provisioningStateTransitionTime":{"Type":4,"Flags":2,"Description":"Time when the provisioning state was changed."},"allocationState":{"Type":142,"Flags":2,"Description":"Allocation state of the cluster. Possible values are: steady - Indicates that the cluster is not resizing. There are no changes to the number of compute nodes in the cluster in progress. A cluster enters this state when it is created and when no operations are being performed on the cluster to change the number of compute nodes. resizing - Indicates that the cluster is resizing; that is, compute nodes are being added to or removed from the cluster."},"allocationStateTransitionTime":{"Type":4,"Flags":2,"Description":"The time at which the cluster entered its current allocation state."},"errors":{"Type":143,"Flags":2,"Description":"Collection of errors encountered by various compute nodes during node setup."},"currentNodeCount":{"Type":3,"Flags":2,"Description":"The number of compute nodes currently assigned to the cluster."},"nodeStateCounts":{"Type":144,"Flags":2,"Description":"Counts of various compute node states on the cluster."}}}},{"6":{"Value":"dedicated"}},{"6":{"Value":"lowpriority"}},{"5":{"Elements":[117,118]}},{"2":{"Name":"ScaleSettings","Properties":{"manual":{"Type":121,"Flags":0,"Description":"Manual scale settings for the cluster."},"autoScale":{"Type":126,"Flags":0,"Description":"Auto-scale settings for the cluster. The system automatically scales the cluster up and down (within minimumNodeCount and maximumNodeCount) based on the number of queued and running jobs assigned to the cluster."}}}},{"2":{"Name":"ManualScaleSettings","Properties":{"targetNodeCount":{"Type":3,"Flags":1,"Description":"The desired number of compute nodes in the Cluster. Default is 0."},"nodeDeallocationOption":{"Type":125,"Flags":0,"Description":"Actions which should be performed when compute nodes are removed from the cluster. Possible values are: requeue (default) - Terminate running jobs and requeue them so the jobs will run again. Remove compute nodes as soon as jobs have been terminated; terminate - Terminate running jobs. The jobs will not run again. Remove compute nodes as soon as jobs have been terminated. waitforjobcompletion - Allow currently running jobs to complete. Schedule no new jobs while waiting. Remove compute nodes when all jobs have completed."}}}},{"6":{"Value":"requeue"}},{"6":{"Value":"terminate"}},{"6":{"Value":"waitforjobcompletion"}},{"5":{"Elements":[122,123,124]}},{"2":{"Name":"AutoScaleSettings","Properties":{"minimumNodeCount":{"Type":3,"Flags":1,"Description":"The minimum number of compute nodes the Batch AI service will try to allocate for the cluster. Note, the actual number of nodes can be less than the specified value if the subscription has not enough quota to fulfill the request."},"maximumNodeCount":{"Type":3,"Flags":1,"Description":"The maximum number of compute nodes the cluster can have."},"initialNodeCount":{"Type":3,"Flags":0,"Description":"The number of compute nodes to allocate on cluster creation. Note that this value is used only during cluster creation. Default: 0."}}}},{"2":{"Name":"VirtualMachineConfiguration","Properties":{"imageReference":{"Type":128,"Flags":0,"Description":"The OS image reference."}}}},{"2":{"Name":"ImageReference","Properties":{"publisher":{"Type":4,"Flags":1,"Description":"Publisher of the image."},"offer":{"Type":4,"Flags":1,"Description":"Offer of the image."},"sku":{"Type":4,"Flags":1,"Description":"SKU of the image."},"version":{"Type":4,"Flags":0,"Description":"Version of the image."},"virtualMachineImageId":{"Type":4,"Flags":0,"Description":"The ARM resource identifier of the virtual machine image for the compute nodes. This is of the form /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/images/{imageName}. The virtual machine image must be in the same region and subscription as the cluster. For information about the firewall settings for the Batch node agent to communicate with the Batch service see https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration. Note, you need to provide publisher, offer and sku of the base OS image of which the custom image has been derived from."}}}},{"2":{"Name":"NodeSetup","Properties":{"setupTask":{"Type":130,"Flags":0,"Description":"Specifies a setup task which can be used to customize the compute nodes of the cluster."},"mountVolumes":{"Type":38,"Flags":0,"Description":"Details of volumes to mount on the cluster."},"performanceCountersSettings":{"Type":133,"Flags":0,"Description":"Performance counters reporting settings."}}}},{"2":{"Name":"SetupTask","Properties":{"commandLine":{"Type":4,"Flags":1,"Description":"The command line to be executed on each cluster's node after it being allocated or rebooted. The command is executed in a bash subshell as a root."},"environmentVariables":{"Type":131,"Flags":0,"Description":"A collection of user defined environment variables to be set for setup task."},"secrets":{"Type":132,"Flags":0,"Description":"A collection of user defined environment variables with secret values to be set for the setup task. Server will never report values of these variables back."},"stdOutErrPathPrefix":{"Type":4,"Flags":1,"Description":"The prefix of a path where the Batch AI service will upload the stdout, stderr and execution log of the setup task."},"stdOutErrPathSuffix":{"Type":4,"Flags":2,"Description":"A path segment appended by Batch AI to stdOutErrPathPrefix to form a path where stdout, stderr and execution log of the setup task will be uploaded. Batch AI creates the setup task output directories under an unique path to avoid conflicts between different clusters. The full path can be obtained by concatenation of stdOutErrPathPrefix and stdOutErrPathSuffix."}}}},{"3":{"ItemType":66}},{"3":{"ItemType":68}},{"2":{"Name":"PerformanceCountersSettings","Properties":{"appInsightsReference":{"Type":134,"Flags":1,"Description":"Azure Application Insights information for performance counters reporting."}}}},{"2":{"Name":"AppInsightsReference","Properties":{"component":{"Type":37,"Flags":1,"Description":"Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet."},"instrumentationKey":{"Type":4,"Flags":0,"Description":"Value of the Azure Application Insights instrumentation key."},"instrumentationKeySecretReference":{"Type":41,"Flags":0,"Description":"Key Vault Secret reference."}}}},{"6":{"Value":"creating"}},{"6":{"Value":"succeeded"}},{"6":{"Value":"failed"}},{"6":{"Value":"deleting"}},{"5":{"Elements":[135,136,137,138]}},{"6":{"Value":"steady"}},{"6":{"Value":"resizing"}},{"5":{"Elements":[140,141]}},{"3":{"ItemType":92}},{"2":{"Name":"NodeStateCounts","Properties":{"idleNodeCount":{"Type":3,"Flags":2,"Description":"Number of compute nodes in idle state."},"runningNodeCount":{"Type":3,"Flags":2,"Description":"Number of compute nodes which are running jobs."},"preparingNodeCount":{"Type":3,"Flags":2,"Description":"Number of compute nodes which are being prepared."},"unusableNodeCount":{"Type":3,"Flags":2,"Description":"Number of compute nodes which are in unusable state."},"leavingNodeCount":{"Type":3,"Flags":2,"Description":"Number of compute nodes which are leaving the cluster."}}}},{"4":{"Name":"Microsoft.BatchAI/workspaces/clusters@2018-05-01","ScopeType":8,"Body":115}}]